# 模型修改日志

[toc]

| date | MAP   | MAP50 | MAP75 | s     | m     | l     | score      | model   | loss |
| ---- | ----- | ----- | ----- | ----- | ----- | ----- | ---------- | ------- | ---- |
|      |       |       |       |       |       |       |            |         |      |
| 3/6  | 0.465 | 0.833 | 0.465 | 0.229 | 0.44  | 0.513 | 0.42745937 | faster  |      |
| 3/5  | 0.401 | 0.689 | 0.433 | 0.149 | 0.367 | 0.462 | 0.34733043 | cascade |      |
| 3/4  | 0.405 | 0.702 | 0.429 | 0.157 | 0.372 | 0.468 | 0.35986083 | cascade | 1.0  |
| 3/3  | 0.475 | 0.832 | 0.497 | 0.224 | 0.448 | 0.528 | 0.39238524 | cascade | 0.6  |

## 20200303

**Config**

| baseline                 | lr   | step    | anchor_ratios             | ima_scale   |
| ------------------------ | ---- | ------- | ------------------------- | ----------- |
| cascade_rcnn_dcn_r50_fpn | 0.02 | [8, 11] | [0.2, 0.5, 1.0, 2.0, 5.0] | (1080, 920) |

+ 观测数据，发现数据集多呈序列分布，若用随机抽样可能会因场景分布产生误差，故采用间隔抽样，按照0.85：0.15的比例切分训练集和验证集

+ 验证序列抽样后，训练集、验证集、原始数据集各目标分布基本保持不变

| dataset | holothurian | echinus | scallop | starfish |
| ------- | ----------- | ------- | ------- | -------- |
| org     | 5537        | 22343   | 6720    | 6814     |
| train   | 4574        | 18676   | 5554    | 5704     |
| val     | 963         | 3667    | 1166    | 1137     |

+ 针对图像大小分布情况，当时选取了靠近(720,405)，且略大的分辨率，mmdet保持比例不变

  ![1583591299153](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583591299153.png)

这里疑似会出问题，若图像大小为(3840,2160)，resize到(1080, 920)，图像缩小3.5倍，可能会删除较小标注框

结果图

![1583592005705](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583592005705.png)

**结论：**

1. 修改学习率意义不大，模型拟合较好，map和损失都较早趋于稳定

## 20200304

**Config**

| baseline                 | lr   | step    | anchor_ratios             | ima_scale   |
| ------------------------ | ---- | ------- | ------------------------- | ----------- |
| cascade_rcnn_dcn_r50_fpn | 0.02 | [8, 11] | [0.2, 0.5, 1.0, 2.0, 5.0] | (1080, 920) |

+ 引入了OHEM，在线难样本挖掘，在cascade的三个阶段。本想使用focal loss，但focal loss的根本目的是解决one-stage中，正负样本分布不均衡，简单负样本过多，导致模型收敛更快，但却没有很好拟合困难正样本的知识。使用的cascade网络，本身是two-stage，已经解决了正负样本分布不均衡的问题
+ 其他什么都没有改，模型在验证集下降了0.07个点，在平台得分下降了0.04个点，**OHEM不是直接改了就能用，需要读一下原文，了解适用环境**

![1583592621770](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583592621770.png)

**结论：**

1. 看loss曲线，模型欠拟合，且下降幅度较小，感觉可以略微提高学习率，增加训练epoch
2. 引入OHEM，损失先上升，后下降。map的起点精度均降低 (mAP: 0.34 ->0.22)

## 20200305

**Config**

| baseline                 | lr   | step     | anchor_ratios             | ima_scale   |
| ------------------------ | ---- | -------- | ------------------------- | ----------- |
| cascade_rcnn_dcn_r50_fpn | 0.04 | [16, 19] | [0.2, 0.5, 1.0, 2.0, 5.0] | (1080, 920) |

+ backbone换成了 ResNet101
+ 采样器依然是OHEMSampler
+ 提高学习率0.02->0.04
+ 增加了训练周期到22个epoch

![1583593178075](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583593178075.png)

**总结：**

1. 1-5个epoch，使用四个GPU，一个epoch迭代285次
   6-22个epoch，使用两个GPU，一个epoch迭代570次
2. 增大学习率，算法在1-5个epoch损失下降于4日相比没有明显变化，均为1.2左右。提高了学习率网络并非收敛更快，反而更早的趋于稳定，感觉学习率给大了，学习率降低后，网络还是可以降到0.9的损失，**且mAP与4日差别不大**，**ResNet从50->101，没有发挥作用，OHEM没有配合默契，限制了模型表达**
3. mAP起点更低，在第16个epoch更新学习率，损失有明显下降，MAP有明显提升，但随后趋于稳定，在第19个epoch更新学习率，从损失上看略早，**还可以延后**，学习率降低后，网络趋于稳定，可能是train不动了



## 20200306

**Config**

| baseline                | lr   | step    | anchor_ratios             | ima_scale   |
| ----------------------- | ---- | ------- | ------------------------- | ----------- |
| faster_rcnn_dcn_r50_fpn | 0.02 | [8, 11] | [0.2, 0.5, 1.0, 2.0, 5.0] | (1080, 920) |

+ 原基础上加了anchor_ratios = [0.2, 0.5, 1.0, 2.0, 5.0]
+ 使用RandomSampler作为抽样器，未修改
+ 训练尺度，使用当前最优尺度(1080, 920)
+ 预训练权重使用的faster_rcnn_r50_fpn_1x_cls_24.pth，并非dcn的权重

![1583595721774](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583595721774.png)

**总结：**

1. faster-rcnn损失起点更低，但是这与cascade的损失没有对比意义
2. 在第8个epoch调整学习率（4600次iter左右），损失有略微下降，第11次修改学习率，损失基本不变，模型拟合较好
3. 在第8个epoch调整学习率，map有略微升高，后趋于稳定
4. 这是目前最优baseline，考虑在此基础上做两个试验
   + **使用dcn的预训练权重，其他参数不变  --1**
   + **使用原始ratio，其他参数不变     --2**
   + **使用多尺度训练，只修改短边，多尺度使用推荐尺度(1300, 1200)  (1300, 800)  测试使用(1300,1000) --3**

## 20200307

**Config**

| baseline                 | lr   | step    | anchor_ratios             | ima_scale   |
| ------------------------ | ---- | ------- | ------------------------- | ----------- |
| cascade_rcnn_dcn_r50_fpn | 0.02 | [8, 11] | [0.2, 0.5, 1.0, 2.0, 5.0] | (1080, 920) |

+ 使用初始的cascade_r50训练
+ 使用RandomSampler作为抽样器，未修改
+ 添加了多尺度训练，使用两个尺度img_scale=[(1920, 1080), (720, 405)]， 测试的是scale使用的(1920, 1080)
+ 加载的预训练文件出现问题，加载的r101的预训练文件cascade_rcnn_dconv_c3-c5_r101_fpn_1x

![1583596919791](C:\Users\60155\AppData\Roaming\Typora\typora-user-images\1583596919791.png)

总结：

1. 经过eda， (720, 405)的图像更多，可尝试测试时使用(720, 405)或(1080, 920)进行
2. 与3月3日对比，多尺度下，网络的损失起点更低
3. 在第七次更新学习率时，网络的损失还在下降，网络还没稳定，应延后调整学习率
4. 但从map来看，网络最终趋于稳定