## 实验记录
#### 艾宏峰

当前baseline模型最优配置如下：

|配置|设置|
|:---:|:---:|
|模型|Faster R-CNN + r50 + FPN + DCN|
|anchor_ratio|[0.2, 0.5, 1.0, 2.0, 5.0]|
|训练多尺度|[(4096, 800), (4096, 1200)]|
|测试尺度|(4096, 1000)|
|NMS|soft_nms (min_score=0.001, max_per_img = 100)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|未开启|
|score|0.46365661|
|MAP/MAP50/MAP75|0.500/0.851/0.536|
****
### 2020年3月11日
1. 实验1主要是研究**libra**：  

|libra|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|无|0.500|0.851|0.536|**0.4637**|0.24|
|有|0.509|0.855|0.558|0.4618|0.46|

**总结**：Libra的初衷是解决训练中样本层，特征层和目标层的不平衡问题。分数略低一点的原因可能是当前数据量和数据的现有特征决定了模型的上限，虽然Libra在验证集上表现好，但可能存在验证集过拟合嫌疑。建议后续先在数据上下工夫，再考虑提高模型的复杂度。

### 2020年3月12日
1. 实验2主要是研究**allowed_border和neg_pos_ub**：  

|allowed_border|neg_pos_ub|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|0|-1|0.500|0.851|0.536|**0.4637**|0.24|
|-1|3|0.503|0.854|0.537|0.4632|0.26|

注：neg_pos_ub=-1是指RPN是不对‘负样本/正样本’比率作限制，而neg_pos_ub=3是指负样本数最多是正样本数3倍。allowed_border=0是指超过图片边界的anchor将会被忽略，allowed_border=-1是不忽略。  

**总结**：按mmdetection论文说法实验2会提高了AR，而且论文提到在靠近边界的GT目标能够在训练中有更多匹配正样本，此外，数据集上有些海产就在图片边缘附近，但最后这种配置并没有带来提升，猜想原因是之前加入了更小的anchor ratio，这样边缘目标也能被更好的召回，所以这么没有提升。

### 2020年3月13日
1. 实验3主要是研究**群内选手提供的方案**:  

|配置|设置|
|:---:|:---:|
|模型|Cascade R-CNN + ResNeXt101 + FPN + DCN|
|anchor_ratio|[0.5, 1.0, 2.0]|
|训练多尺度|[(4096, 600), (4096, 1000)]|
|测试多尺度|[(4096, 600), (4096, 800), (4096, 1000)]|
|NMS|soft_nms (min_score=0.0001, max_per_img = 200)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|开启|
|预训练模型|HTC|
|score|0.4841776|
|MAP50|0.867|

|baseline|MAP50|score|loss|
|:---:|:---:|:---:|:---:|
|我们|0.851|0.4637|0.24|
|郑烨|0.867|**0.4842**|0.54|

**总结**：郑烨大大提高了模型复杂度。相比我们，他提供的方案中模型更复杂，图像尺度更大更多变，NMS更宽松，也因为如此运行时间更长，为此他开启了混合精度训练的方法（通过16位浮点数（FP16）进行深度学习模型训练，从而减少了训练深度学习模型所需的内存，同时由于FP16的运算比FP32运算更快，从而也进一步提高了硬件效率），后续实验暂时在该基础上扩展实验内容。

### 2020年3月15日
1. 实验4主要是研究**训练开启的翻转增强**:

|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|开启|未开启|-|0.867|-|**0.4842**|0.54|
|开启|开启|0.514|0.855|0.565|0.4788|0.46|

注：翻转概率均为0.5。

**总结**：追加垂直翻转不能带来表现提升，可能是因为加入垂直翻转的训练集中场景与测试集正常采集场景有些不一致引起的。暂时后续**不考虑垂直翻转**。  

### 2020年3月16日
1. 实验5主要是研究**实例平衡增强 (Instance-Balanced Augmentation)**:

|实例平衡增强|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|未开启|-|0.867|-|**0.4842**|0.54|
|开启|0.516|0.856|0.570|**0.4569**|0.2070|

**总结**：由于原数据集存在类别不平衡问题（实例数量：海参4574，海胆18676，扇贝5554和海星5704），所以打算使用阿里之前提出的一个实例平衡增强方法去增强数据解决不平衡问题，首先先把原图放大1.5倍，然后用原图原始尺寸大小作为滑窗大小，以滑窗形式水平平均地移动三次，垂直平均地移动三次，最后1张图会得到9张相当于shift和scale后的增强图片。在滑动中发现如果不对滑动窗口做限制，会加重类别不平衡，因为海胆数量太多，且滑动结果会有很多单张只有一个扇贝的情况从而导致扇贝很多。因此对滑动窗口进行限制：滑动窗口内含海胆就不要该窗口，滑动窗口内仅有一个扇贝的不要要。最后增强数据和原数据合并后的实例数量是：海参13016，海胆18676，扇贝13287和海星12322。虽然类别平衡许多了且该增强模仿了水下手持拍摄设备从远到近的拍摄过程，但结果反而下降，原因是单纯的实例平衡增强其实有点像重复数据集操作，这一点在‘第一个epoch下验证集比之前实验都高，在第9个epoch验证集表现最好’能反映出来，但是图片并没有很大的变化，最多是解决了模型平移不变性的问题。阿里其实后面还对这些增强图片还加入了一种自动并行增强（Auto Affine Augmentation）方法，即旋转边界框，白平衡，按照x轴或y轴截断等。这块后续有时间可以尝试下。

2. 今天对数据再次深入研究了下，有以下发现：  
- 宽高比1.22的2种采集图片像素低，放大易失真，且部分图片中目标及其密集，海产重叠严重。   
- 宽高比1.77的3中采集图片中，部分图片含有大量密集的扇贝目标或海胆目标（猜测是不同海产放养区所致）。  
- 图片有很多漏标，少扇贝区域的地方即使出现扇贝，也不太会被认真标注，而且因为被沙掩盖部分外壳，标注存在不确定性。而海参由于肉眼本身因海水可见度，辨别难度导致存在一定的漏标。一般从上拍下的海星不会被漏标，但是海底平行拍摄时容易被漏标。海胆漏标不严重，一般都是远处有小黑团的这种情况，可能不会被标注。  
- 数据集中无标注的图片是拍摄结束回到水面过程中记录的视频切片图。  
- 当前最优模型下，AP表现从大到小是：海胆0.92 > 海星0.89 > 扇贝0.85 > 海参 0.80。海胆检测好是因为标注数量多，特征（带刺）明显。海星第二好是因为海星大部分就是一个样，蓝绿角中间橘红色的特征，且一般属于大目标好检测。扇贝检测难度是沙土遮掩，标注不确定性大，小目标。海参难检测原因在于由于海水可见度低导致海参身上的触点较难观察到，而且颜色深沉，在海底环境中不突出，而且容易与条状石头，海洋生物排泄物或断落珊瑚，海草等混淆。
### 2020年3月17日
1. 实验6主要是研究**训练开启的模糊处理（MedianBlur或者Blur）**:

|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|开启|未开启|-|0.867|-|**0.4842**|0.54|
|开启|未开启|0.524|0.862|0.584|**0.4843**|0.6386|

注：模糊概率均为0.1。

**总结**：模糊处理提升效果不大，可能是因为引入噪声引起的。后续**考虑增加模糊概率**。
