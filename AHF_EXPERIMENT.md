## 实验记录
#### 艾宏峰

当前baseline模型最优配置如下：

|配置|设置|
|:---:|:---:|
|模型|Faster R-CNN + r50 + FPN + DCN|
|anchor_ratio|[0.2, 0.5, 1.0, 2.0, 5.0]|
|训练多尺度|[(4096, 800), (4096, 1200)]|
|测试尺度|(4096, 1000)|
|NMS|soft_nms (min_score=0.001, max_per_img = 100)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|未开启|
|score|0.46365661|
|MAP/MAP50/MAP75|0.500/0.851/0.536|
****
### 2020年3月11日
1. 实验1主要是研究**libra**：  

|libra|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|无|0.500|0.851|0.536|**0.4637**|0.24|
|有|0.509|0.855|0.558|0.4618|0.46|

**总结**：Libra的初衷是解决训练中样本层，特征层和目标层的不平衡问题。分数略低一点的原因可能是当前数据量和数据的现有特征决定了模型的上限，虽然Libra在验证集上表现好，但可能存在验证集过拟合嫌疑。建议后续先在数据上下工夫，再考虑提高模型的复杂度。

### 2020年3月12日
1. 实验2主要是研究**allowed_border和neg_pos_ub**：  

|allowed_border|neg_pos_ub|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|0|-1|0.500|0.851|0.536|**0.4637**|0.24|
|-1|3|0.503|0.854|0.537|0.4632|0.26|

注：neg_pos_ub=-1是指RPN是不对‘负样本/正样本’比率作限制，而neg_pos_ub=3是指负样本数最多是正样本数3倍。allowed_border=0是指超过图片边界的anchor将会被忽略，allowed_border=-1是不忽略。  

**总结**：按mmdetection论文说法实验2会提高了AR，而且论文提到在靠近边界的GT目标能够在训练中有更多匹配正样本，此外，数据集上有些海产就在图片边缘附近，但最后这种配置并没有带来提升，猜想原因是之前加入了更小的anchor ratio，这样边缘目标也能被更好的召回，所以这么没有提升。

### 2020年3月13日
1. 实验3主要是研究**群内选手提供的方案**:  

|配置|设置|
|:---:|:---:|
|模型|Cascade R-CNN + ResNeXt101 + FPN + DCN|
|anchor_ratio|[0.5, 1.0, 2.0]|
|训练多尺度|[(4096, 600), (4096, 1000)]|
|测试多尺度|[(4096, 600), (4096, 800), (4096, 1000)]|
|NMS|soft_nms (min_score=0.0001, max_per_img = 200)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|开启|
|预训练模型|HTC|
|score|0.4841776|
|MAP50|0.867|

|baseline|MAP50|score|loss|
|:---:|:---:|:---:|:---:|
|我们|0.851|0.4637|0.24|
|郑烨|0.867|**0.4836**|0.54|

**总结**：郑烨大大提高了模型复杂度。相比我们，他提供的方案中模型更复杂，图像尺度更大更多变，NMS更宽松，也因为如此运行时间更长，为此他开启了混合精度训练的方法（通过16位浮点数（FP16）进行深度学习模型训练，从而减少了训练深度学习模型所需的内存，同时由于FP16的运算比FP32运算更快，从而也进一步提高了硬件效率），后续实验暂时在该基础上扩展实验内容。

### 2020年3月15日
1. 实验4主要是研究**训练开启的翻转增强**:

|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|开启|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|开启|开启|0.514|0.855|0.565|0.4788|0.46|

注：翻转概率均为0.5。

**总结**：追加垂直翻转不能带来表现提升，可能是因为加入垂直翻转的训练集中场景与测试集正常采集场景有些不一致引起的。暂时后续**不考虑垂直翻转**。  

### 2020年3月16日
1. 实验5主要是研究**实例平衡增强 (Instance-Balanced Augmentation)**:

|实例平衡增强|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|开启|0.516|0.856|0.570|0.4569|0.2070|

**总结**：由于原数据集存在类别不平衡问题（实例数量：海参4574，海胆18676，扇贝5554和海星5704），所以打算使用阿里之前提出的一个实例平衡增强方法去增强数据解决不平衡问题，首先先把原图放大1.5倍，然后用原图原始尺寸大小作为滑窗大小，以滑窗形式水平平均地移动三次，垂直平均地移动三次，最后1张图会得到9张相当于shift和scale后的增强图片。在滑动中发现如果不对滑动窗口做限制，会加重类别不平衡，因为海胆数量太多，且滑动结果会有很多单张只有一个扇贝的情况从而导致扇贝很多。因此对滑动窗口进行限制：滑动窗口内含海胆就不要该窗口，滑动窗口内仅有一个扇贝的不要要。最后增强数据和原数据合并后的实例数量是：海参13016，海胆18676，扇贝13287和海星12322。虽然类别平衡许多了且该增强模仿了水下手持拍摄设备从远到近的拍摄过程，但结果反而下降，原因是单纯的实例平衡增强其实有点像重复数据集操作，这一点在‘第一个epoch下验证集比之前实验都高，在第9个epoch验证集表现最好’能反映出来，但是图片并没有很大的变化，最多是解决了模型平移不变性的问题。阿里其实后面还对这些增强图片还加入了一种自动并行增强（Auto Affine Augmentation）方法，即旋转边界框，白平衡，按照x轴或y轴截断等。这块后续有时间可以尝试下。

2. 今天对数据再次深入研究了下，有以下发现：  
- 宽高比1.22的2种采集图片像素低，放大易失真，且部分图片中目标及其密集，海产重叠严重。   
- 宽高比1.77的3中采集图片中，部分图片含有大量密集的扇贝目标或海胆目标（猜测是不同海产放养区所致）。  
- 图片有很多漏标，少扇贝区域的地方即使出现扇贝，也不太会被认真标注，而且因为被沙掩盖部分外壳，标注存在不确定性。而海参由于肉眼本身因海水可见度，辨别难度导致存在一定的漏标。一般从上拍下的海星不会被漏标，但是海底平行拍摄时容易被漏标。海胆漏标不严重，一般都是远处有小黑团的这种情况，可能不会被标注。  
- 数据集中无标注的图片是拍摄结束回到水面过程中记录的视频切片图。  
- 当前最优模型下，AP表现从大到小是：海胆0.92 > 海星0.89 > 扇贝0.85 > 海参 0.80。海胆检测好是因为标注数量多，特征（带刺）明显。海星第二好是因为海星大部分就是一个样，蓝绿角中间橘红色的特征，且一般属于大目标好检测。扇贝检测难度是沙土遮掩，标注不确定性大，小目标。海参难检测原因在于由于海水可见度低导致海参身上的触点较难观察到，而且颜色深沉，在海底环境中不突出，而且容易与条状石头，海洋生物排泄物或断落珊瑚，海草等混淆。

### 2020年3月17日
1. 实验6主要是研究**训练开启的模糊处理（MedianBlur或者Blur）**:

|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|开启|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|开启|未开启|0.524|0.862|0.584|**0.4843**|0.6386|

注：模糊概率均为0.1。

**总结**：模糊处理提升效果不大，可能是因为引入噪声引起的。后续**考虑增加模糊概率**。

### 2020年3月18日
1. 实验7主要是研究**训练使用retinex数据增强**:

|retinex|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|开启|0.522|0.859|0.581|0.4830|0.5483|

注：dict(type='Retinex', model='MSR', sigma=[30, 150, 300], restore_factor=2.0, color_gain=6.0, gain=128.0, offset=128.0)  
**总结**：增强算法也有参数要调，后续有时间应对比下每一类的ap和斩风的每一类ap差距，看是否对海参有增强。

### 2020年3月18日
1. 实验6主要是研究**训练开启one of(CLAHE+IAASharpen+IAAEmboss+RandomBrightnessContrast)**:

|CLAHE|IAASharpen|IAAEmboss|RBC|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|没|没|没|没|0.526|0.863|0.585|0.4836|0.54|
|有|有|有|有|0.526|0.866|0.586|**0.4853**|0.5617|

注：'CLAHE'对比度受限的自适应直方图均衡，clip_limit=2（对比度限制的上阈值）其他均为默认参数.。'IAAEmboss'，压印输入图像，并将结果与原始图像重叠。'IAASharpen'锐化输入图像，并将结果与原始图像重叠。其他均为默认参数.one of概率为0.3，内部概率方法均为0.5。

**总结**：将图像直方均匀和重叠处理对暗部目标有一定效果。后续**分别对四个方法进行深入分析**。


### 2020年3月19日
1. 实验7主要研究**泊松融合Poisson Blending数据增强**：

|泊松融合|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|开启|0.508|0.851|0.558|未提交|0.52|

注：该对比实验组没加其他Albu手段。  
**总结**：在之前实验中发现海参检测效果差，受论文[UDD: An Underwater Open-sea Farm Object Detection Dataset for Underwater Robot Picking](https://arxiv.org/abs/2003.01446)启发：“海参和扇贝因为训练样本不足和数据类别不平衡问题导致很多模型表现不好”。因此实验7针对宽高为720和405的图片进行海参目标的数据增强工作（采用该尺寸的图片有两点原因：一是图片第二大，处理速度快不像第一大尺寸的图片，处理慢且耗内存。二是单独对这类图片融合后背景差异不会太大，避免融合突兀）。由于海参问题严重，所以只针对抠取了900多个海参，然后选取单图标注数量不超过4的图片作为融合海参的背景图片（单图过多标注可能会影响放置粘贴目标和带来冗余的目标加重类别不平衡问题）。之后根据融合后可视化结果将2616张增强图人工剔除剩1441张融合较好的图加入到原始数据集中进行训练。最后增强后各类别数据是：海参（4574变到6991），海胆（18676到20818），扇贝（5554到5653）和海星（5704到6326）。模型最后的表现并没有提升，即使是海参的AP也没增加，猜测原因是：融合的还是有些许不自然，容易使模型过拟合，而且这里并没有使用新的背景图片，而是原数据的图片，这也导致一些背景和目标重复出现，影响模型通用性的提升。

### 2020年3月20日
1. 实验8主要研究是**去除长短比为1.22的数据集**:

|长短边1.22图|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|有|0.526|0.863|0.585|**0.4836**|0.52|
|无|0.526|0.863|0.590|未提交|0.49|

注：去除长短比为1.22的数据集是指不将（704,576）和（586,480）这两种尺寸图片（后续简称122图片）的加入到模型训练中。

**总结**: 经过进一步EDA发现：122图片与177图片是不同类设备采集得到的，而且训练集中122图片（共有82张）的各类别数量是：海参1个，海胆632个，扇贝和海星都是20个。而测试集图片尺寸情况如下：

|测试集图片尺寸（h,w）|长短边比|图片数量|
|:---:|:---:|:---:|
|(1080,1920)|1.77|42|
|(1440,2560)|1.77|32|
|**(1536,2048)**|**1.33**|**21**|
|(2160,3840)|1.77|653|
|(405,720)|1.77|52|

后面特意抽取看了长短边比为1.33的1536x2048图，发现其跟训练集122图片有些类似，猜测是同一类的设备，但是测试集中133图片（均为2018年拍摄）目测比训练集中122图（均为2017年拍摄）有更多的扇贝，且图片像素更大了，猜测是设备升级了。因为没有提交结果暂不下结论。  

2. 实验9主要研究是**在3月18日的最佳得分上进行了全数据集训练**：

|数据集|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|
|训练集模型|0.526|0.866|0.586|**0.4853**|0.5617|
|全数据集模型|0.600|0.922|0.708|**0.4856**|0.54|

注：提升不大，说明训练集的分布基本囊括了验证集的分布

### 2020年3月21日
1. 实验10主要研究是**anchor_ratio增加0.2和allowed_border=-1**：

|achor_ratio|allowed_border|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|无0.2|0|0.526|0.863|0.585|**0.4836**|0.54|
|加0.2|-1|0.527|0.866|0.593|0.4819|0.62|

注：allowed_border=-1允许模型RPN在图片边缘提出超出边缘的框。

**总结**：虽然增强模型在边缘目标的表现能力和小目标检测能力在验证集上有提升，但提交结果反而下降了，猜测原因是由于测试集存在部分数据不属于训练集分布下，所以有可能实验10过拟合了验证集，后续实验应该注意提高模型通用性。
